{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "World Development Indicators - worldbank.org <br/>\nFabio Cardoso - Dec/2021 <br/><br/>\n\nDatasets: <br/><br/>\n\nCountry Indicators: <br/>\nhttps://datacatalog.worldbank.org/search/dataset/0037712/World-Development-Indicators <br/>\nNote: dataset updated with the topics presented in https://data.worldbank.org/indicator?tab=all - Utils notebook. <br/><br/>\n\nCountry Codes ISO 3166: <br/>\nhttps://www.iban.com/country-codes <br/><br/>\n\nNote: <br/>\nFor some orphans indicators, the topic 'private-sector' was assumed - Utils notebook. <br/>\n. Firms visited or required meetings with tax officials (% of firms) <br/>\n. Net ODA provided to the least developed countries (% of GNI) <br/>\n. Net ODA provided, to the least developed countries (current US )\u2212\ud835\udc41\ud835\udc52\ud835\udc61\ud835\udc42\ud835\udc37\ud835\udc34\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc63\ud835\udc56\ud835\udc51\ud835\udc52\ud835\udc51,\ud835\udc61\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59(\u2212\ud835\udc41\ud835\udc52\ud835\udc61\ud835\udc42\ud835\udc37\ud835\udc34\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc63\ud835\udc56\ud835\udc51\ud835\udc52\ud835\udc51,\ud835\udc61\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59(\ud835\udc50\ud835\udc5c\ud835\udc5b\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5b\ud835\udc612015\ud835\udc48\ud835\udc46) <br/>\n. Net ODA provided, total (current US$)"
        },
        {
            "cell_type": "code",
            "execution_count": 69,
            "metadata": {},
            "outputs": [],
            "source": "# Parameters\n\ncloud = True\ntopic = 'general'\nkey_in ='WDI treated-step5-'+topic+'.sav'\nkey1_out = 'wdi_clusters_'+topic+'.parquet' #saving for sqlquery/cognos analytics\nkey2_out = 'wdi_clusters_'+topic+'.csv' #saving local for cognos embedded\nclusterkm_field_name = 'cluster_km_'+topic\nclusterdb_field_name = 'cluster_db_'+topic\nclustergm_field_name = 'cluster_gm_'+topic\neps = 97 #EPC in DBScan algorithm influence dimensions quantity. "
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "metadata": {},
            "outputs": [],
            "source": "# Imports\n\nimport pandas as pd\nimport numpy as np\nimport zipfile\nimport matplotlib.pyplot as plt\nimport zlib\nimport pickle\nfrom threading import Thread\nfrom multiprocessing import Pool\nimport time\nfrom datetime import datetime\nfrom sklearn.preprocessing import MinMaxScaler\n\n#for clustering\nfrom sklearn.cluster import KMeans\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.mixture import GaussianMixture\n\n#for dimentionaluty reduction\nfrom sklearn.decomposition import PCA, TruncatedSVD\nfrom sklearn.manifold import Isomap, LocallyLinearEmbedding, LocallyLinearEmbedding\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\n# Library for sav reading\n!pip install pyreadstat\n\n# Library used in the dataframe compatibility with parquet format\n!pip install unidecode"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": 73,
            "metadata": {},
            "outputs": [],
            "source": "# Storage instantiation\n\nif cloud:\n    import types\n    import pandas as pd\n    import ibm_boto3\n    from botocore.client import Config\n\n    def __iter__(self): return 0\n\n    cnx_fcsinsights = ibm_boto3.client(\n        service_name = 's3',\n        ibm_api_key_id = parm_ibm_api_key_id,\n        ibm_service_instance_id = parm_ibm_service_instance_id,\n        ibm_auth_endpoint = parm_ibm_auth_endpoint,\n        config = Config(signature_version='oauth'),\n        endpoint_url = parm_endpoint_url\n    )\n\nbkt_in = parm_bkt_in\nbkt_out = parm_bkt_out"
        },
        {
            "cell_type": "code",
            "execution_count": 74,
            "metadata": {},
            "outputs": [],
            "source": "# Read data\n\nif cloud:\n    cnx_fcsinsights.download_file(Bucket=bkt_in, Key=key_in, Filename=key_in)\n    df = pd.read_spss(key_in)\nelse:\n    df = pd.read_spss('F:/WDI Working Files/'+key_in)"
        },
        {
            "cell_type": "code",
            "execution_count": 75,
            "metadata": {},
            "outputs": [],
            "source": "# Clustering Kmeans\n\nkmeans = KMeans(n_clusters=5, random_state=0)\nclusterskm = kmeans.fit_predict(df.drop(columns=['Country_Code']).values)\ndf[clusterkm_field_name] = clusterskm"
        },
        {
            "cell_type": "code",
            "execution_count": 76,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "cluster_db_general\n-1    140\n 0     30\n 1     24\n 2     16\n 3      5\nName: Country_Code, dtype: int64"
                    },
                    "execution_count": 76,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# Clustering DBScan\n\ndbscan = DBSCAN(eps=97)\nclustersdb = dbscan.fit_predict(df.drop(columns=['Country_Code']).values)\ndf[clusterdb_field_name] = clustersdb\ndf.groupby(by=[clusterdb_field_name]).count()[df.columns[0]]"
        },
        {
            "cell_type": "code",
            "execution_count": 77,
            "metadata": {},
            "outputs": [],
            "source": "# For GM, it is necessary to apply dimentionality reduction (memory issue).\n\npca = PCA(n_components = df['Country_Code'].nunique())\npc = pca.fit_transform(df.drop(columns=['Country_Code']), df['Country_Code'])"
        },
        {
            "cell_type": "code",
            "execution_count": 78,
            "metadata": {},
            "outputs": [],
            "source": "# Clustering Gaussian Mixture\n\ngaussian = GaussianMixture(n_components=5)\nclustersgm = gaussian.fit_predict(pc)\ndf[clustergm_field_name] = clustersgm"
        },
        {
            "cell_type": "code",
            "execution_count": 79,
            "metadata": {},
            "outputs": [],
            "source": "# Maintaining the main fields for presentation\n\ndf = df[['Country_Code', clusterkm_field_name, clusterdb_field_name, clustergm_field_name]]"
        },
        {
            "cell_type": "code",
            "execution_count": 80,
            "metadata": {},
            "outputs": [],
            "source": "# Aligning clusters by their size order\n\nclusters_km_index = df.groupby(by=[clusterkm_field_name]).count()[df.columns[0]].index.values\nclusters_km_sizes = df.groupby(by=[clusterkm_field_name]).count()[df.columns[0]].values\nclusters_km_order = np.take_along_axis(clusters_km_index, np.argsort(clusters_km_sizes), axis=0)\n\nclusters_db_index = df.groupby(by=[clusterdb_field_name]).count()[df.columns[0]].index.values\nclusters_db_sizes = df.groupby(by=[clusterdb_field_name]).count()[df.columns[0]].values\nclusters_db_order = np.take_along_axis(clusters_db_index, np.argsort(clusters_db_sizes), axis=0)\n\nclusters_gm_index = df.groupby(by=[clustergm_field_name]).count()[df.columns[0]].index.values\nclusters_gm_sizes = df.groupby(by=[clustergm_field_name]).count()[df.columns[0]].values\nclusters_gm_order = np.take_along_axis(clusters_gm_index, np.argsort(clusters_gm_sizes), axis=0)\n\ni=0\nfor clu in clusters_km_order:\n    i +=1\n    df[clusterkm_field_name] = df[clusterkm_field_name].apply(lambda x: i+1000 if x==clu else x)\ndf[clusterkm_field_name] = df[clusterkm_field_name].apply(lambda x: x-1000)\n\ni=0\nfor clu in clusters_db_order:\n    i +=1\n    df[clusterdb_field_name] = df[clusterdb_field_name].apply(lambda x: i+1000 if x==clu else x)\ndf[clusterdb_field_name] = df[clusterdb_field_name].apply(lambda x: x-1000)\n\ni=0\nfor clu in clusters_gm_order:\n    i +=1\n    df[clustergm_field_name] = df[clustergm_field_name].apply(lambda x: i+1000 if x==clu else x)\ndf[clustergm_field_name] = df[clustergm_field_name].apply(lambda x: x-1000)"
        },
        {
            "cell_type": "code",
            "execution_count": 82,
            "metadata": {},
            "outputs": [],
            "source": "# Remove spaces from column names\n\nimport unidecode\ndef remove_space_from_cols_names(df):\n    rens = dict()\n    for col in df.columns:\n        col1 = col.lower() #lowercase\n        col2 = col1.replace(\" \", \"_\") #remove espa\u00e7o\n        col3 = unidecode.unidecode(col2) #remove acento\n        rens.update({col:col2})\n    return df.rename(columns=rens)\n\ndf = remove_space_from_cols_names(df)"
        },
        {
            "cell_type": "code",
            "execution_count": 83,
            "metadata": {},
            "outputs": [],
            "source": "# Save result for presentation\n\nif cloud:\n    df.to_parquet(key1_out, index=False)\n    cnx_fcsinsights.upload_file(Bucket=bkt_out, Key=key1_out, Filename=key1_out)\nelse:\n    df.to_parquet('F:/WDI Working Files/'+key1_out, index=False)"
        },
        {
            "cell_type": "code",
            "execution_count": 84,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Saving local\n\nif cloud:\n    df.to_csv(key2_out, index=False)\n    cnx_local.upload_file(Bucket=bucket, Key=key2_out, Filename=key2_out)"
        },
        {
            "cell_type": "code",
            "execution_count": 85,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "ok\n"
                }
            ],
            "source": "print('ok')"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.9",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}